\hypertarget{namespacenn__regression}{}\doxysection{nn\+\_\+regression Namespace Reference}
\label{namespacenn__regression}\index{nn\_regression@{nn\_regression}}
\doxysubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
def \mbox{\hyperlink{namespacenn__regression_aea3f67f21d46358fe3c1bd1690060f15}{create\+\_\+datasets}} (data, features, target, frac=0.\+5)
\item 
def \mbox{\hyperlink{namespacenn__regression_a9b5a9b723a5584e5a2eec86fff6c6fb4}{normalize}} (data)
\item 
def \mbox{\hyperlink{namespacenn__regression_a2e26d5154e94b7c3da40fa67bb4f40f3}{build\+\_\+model}} (normalizer, layers, input\+\_\+dim=2, activation=\textquotesingle{}relu\textquotesingle{}, optimizer=\textquotesingle{}adam\textquotesingle{}, loss=\textquotesingle{}mean\+\_\+squared\+\_\+error\textquotesingle{})
\item 
def \mbox{\hyperlink{namespacenn__regression_aed2a366f1c82dc4d585dd1c4be5b7081}{learning\+\_\+curve}} (losses, ax=plt.\+gca(), log=False, y=\char`\"{}Loss\char`\"{}, title=\char`\"{}Learning curve and convergence time\char`\"{})
\item 
def \mbox{\hyperlink{namespacenn__regression_a524c7439cb436db4f3ba780f9e4eeba7}{convergence\+\_\+time}} (losses)
\item 
def \mbox{\hyperlink{namespacenn__regression_ab72d507790e1a67912ae3a2bd56a1943}{retransform}} (data, predicted\+\_\+target, target\+\_\+keys=\mbox{[}\char`\"{}Barrier\char`\"{}\mbox{]})
\end{DoxyCompactItemize}
\doxysubsection*{Variables}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{namespacenn__regression_acfc45d24e172f25530e370273822746b}\label{namespacenn__regression_acfc45d24e172f25530e370273822746b}} 
{\bfseries data} = pash\+\_\+to\+\_\+dataframe(\char`\"{}data/pash/large\+\_\+pash.\+dat\char`\"{})
\item 
\mbox{\Hypertarget{namespacenn__regression_a9db469f8446812910ff59a7e4d920f44}\label{namespacenn__regression_a9db469f8446812910ff59a7e4d920f44}} 
{\bfseries frac}
\item 
\mbox{\Hypertarget{namespacenn__regression_a33f9185dbddf8b7e86f4e061cbfee650}\label{namespacenn__regression_a33f9185dbddf8b7e86f4e061cbfee650}} 
def {\bfseries normalizer} = \mbox{\hyperlink{namespacenn__regression_a9b5a9b723a5584e5a2eec86fff6c6fb4}{normalize}}(train\+\_\+features)
\item 
\mbox{\Hypertarget{namespacenn__regression_a3b8117ba0fe65b30415c1178189bb54d}\label{namespacenn__regression_a3b8117ba0fe65b30415c1178189bb54d}} 
def {\bfseries model} = \mbox{\hyperlink{namespacenn__regression_a2e26d5154e94b7c3da40fa67bb4f40f3}{build\+\_\+model}}(normalizer, \mbox{[}150, 150, 150\mbox{]}, optimizer=\char`\"{}adamax\char`\"{})
\item 
\mbox{\Hypertarget{namespacenn__regression_ad8d87687986e09459e38906423d8ce6c}\label{namespacenn__regression_ad8d87687986e09459e38906423d8ce6c}} 
def {\bfseries losses} = model.\+fit(train\+\_\+features, train\+\_\+labels, epochs=1000).history\mbox{[}\textquotesingle{}loss\textquotesingle{}\mbox{]}
\item 
\mbox{\Hypertarget{namespacenn__regression_abab4a73135331645e4eaa3078f97a5cf}\label{namespacenn__regression_abab4a73135331645e4eaa3078f97a5cf}} 
{\bfseries y}
\item 
\mbox{\Hypertarget{namespacenn__regression_a3bbac3571bb59f821ba7e48343d3cc97}\label{namespacenn__regression_a3bbac3571bb59f821ba7e48343d3cc97}} 
{\bfseries log}
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{DoxyVerb}Functions to manipulate DataFrames for a keras fit, to build models quickly and work on the learning curves
\end{DoxyVerb}
 

\doxysubsection{Function Documentation}
\mbox{\Hypertarget{namespacenn__regression_a2e26d5154e94b7c3da40fa67bb4f40f3}\label{namespacenn__regression_a2e26d5154e94b7c3da40fa67bb4f40f3}} 
\index{nn\_regression@{nn\_regression}!build\_model@{build\_model}}
\index{build\_model@{build\_model}!nn\_regression@{nn\_regression}}
\doxysubsubsection{\texorpdfstring{build\_model()}{build\_model()}}
{\footnotesize\ttfamily def nn\+\_\+regression.\+build\+\_\+model (\begin{DoxyParamCaption}\item[{}]{normalizer,  }\item[{}]{layers,  }\item[{}]{input\+\_\+dim = {\ttfamily 2},  }\item[{}]{activation = {\ttfamily \textquotesingle{}relu\textquotesingle{}},  }\item[{}]{optimizer = {\ttfamily \textquotesingle{}adam\textquotesingle{}},  }\item[{}]{loss = {\ttfamily \textquotesingle{}mean\+\_\+squared\+\_\+error\textquotesingle{}} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Takes a normalizer adapted to input, the form of neural network, the dimension of input
and the choice of activation function, optimizer and loss function.
Returns a compiled keras model.
:param normalizer: (keras normalizer object) normalizer
:param layers: (int list) [m,n,..] meaning a first hidden layer with m neurones, a second with n neurones, etc.
:param input_dim: (int) number of features
:param activation: (str) neuron's activation function
:param optimizer: (str) optimizer used to compile
:return model: (keras model) compiled model
\end{DoxyVerb}
 \mbox{\Hypertarget{namespacenn__regression_a524c7439cb436db4f3ba780f9e4eeba7}\label{namespacenn__regression_a524c7439cb436db4f3ba780f9e4eeba7}} 
\index{nn\_regression@{nn\_regression}!convergence\_time@{convergence\_time}}
\index{convergence\_time@{convergence\_time}!nn\_regression@{nn\_regression}}
\doxysubsubsection{\texorpdfstring{convergence\_time()}{convergence\_time()}}
{\footnotesize\ttfamily def nn\+\_\+regression.\+convergence\+\_\+time (\begin{DoxyParamCaption}\item[{}]{losses }\end{DoxyParamCaption})}

\begin{DoxyVerb}Takes a list of losses and returns the start epoch from which the loss has been smaller or equal to the
mean loss at the end for at least 10 epochs or simply returns the last epoch.
Considers that the epochs range from (0, len(losses)).
:param losses: (float list) History.history['loss'] from output of a fit
\end{DoxyVerb}
 \mbox{\Hypertarget{namespacenn__regression_aea3f67f21d46358fe3c1bd1690060f15}\label{namespacenn__regression_aea3f67f21d46358fe3c1bd1690060f15}} 
\index{nn\_regression@{nn\_regression}!create\_datasets@{create\_datasets}}
\index{create\_datasets@{create\_datasets}!nn\_regression@{nn\_regression}}
\doxysubsubsection{\texorpdfstring{create\_datasets()}{create\_datasets()}}
{\footnotesize\ttfamily def nn\+\_\+regression.\+create\+\_\+datasets (\begin{DoxyParamCaption}\item[{}]{data,  }\item[{}]{features,  }\item[{}]{target,  }\item[{}]{frac = {\ttfamily 0.5} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Takes full DataFrame directly transformed from a pash.dat file
and keys of interest to return training and testing datasets.
:param data: (pandas DataFrame) DataFrame of a pash.dat file
:param features: (str list) keys of features
:param target: (str) key of target
:param frac: (float) fraction of the data turned into training set - half by default
:return train_data: (pandas DataFrames) training set with columns corresponding to features and target
:return test_data: (pandas DataFrames) test set with columns corresponding to features and target
:return train_features: (pandas DataFrames) training set with columns corresponding to features
:return train_target: (pandas DataFrames) training set with column corresponding to target
:return test_features: (pandas DataFrames) test set with columns corresponding to features
:return test_target: (pandas DataFrames) test set with column corresponding to target
\end{DoxyVerb}
 \mbox{\Hypertarget{namespacenn__regression_aed2a366f1c82dc4d585dd1c4be5b7081}\label{namespacenn__regression_aed2a366f1c82dc4d585dd1c4be5b7081}} 
\index{nn\_regression@{nn\_regression}!learning\_curve@{learning\_curve}}
\index{learning\_curve@{learning\_curve}!nn\_regression@{nn\_regression}}
\doxysubsubsection{\texorpdfstring{learning\_curve()}{learning\_curve()}}
{\footnotesize\ttfamily def nn\+\_\+regression.\+learning\+\_\+curve (\begin{DoxyParamCaption}\item[{}]{losses,  }\item[{}]{ax = {\ttfamily plt.gca()},  }\item[{}]{log = {\ttfamily False},  }\item[{}]{y = {\ttfamily \char`\"{}Loss\char`\"{}},  }\item[{}]{title = {\ttfamily \char`\"{}Learning~curve~and~convergence~time\char`\"{}} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Takes the list of losses and plots it as a function of epochs with a vertical line at convergence.
:param losses: (float list) History.history['loss'] from output of a fit
:param ax: (axes) plt.gca() by default
:param log: (bool) If True the plot is in log scale
:param title: (str) Title of the plot
\end{DoxyVerb}
 \mbox{\Hypertarget{namespacenn__regression_a9b5a9b723a5584e5a2eec86fff6c6fb4}\label{namespacenn__regression_a9b5a9b723a5584e5a2eec86fff6c6fb4}} 
\index{nn\_regression@{nn\_regression}!normalize@{normalize}}
\index{normalize@{normalize}!nn\_regression@{nn\_regression}}
\doxysubsubsection{\texorpdfstring{normalize()}{normalize()}}
{\footnotesize\ttfamily def nn\+\_\+regression.\+normalize (\begin{DoxyParamCaption}\item[{}]{data }\end{DoxyParamCaption})}

\begin{DoxyVerb}Takes a DataFrame and returns an adapted Keras normalizer.
:param data: (pandas DataFrame) features DataFrame to normalize
:return normalizer: (keras normalizer object) normalizer
\end{DoxyVerb}
 \mbox{\Hypertarget{namespacenn__regression_ab72d507790e1a67912ae3a2bd56a1943}\label{namespacenn__regression_ab72d507790e1a67912ae3a2bd56a1943}} 
\index{nn\_regression@{nn\_regression}!retransform@{retransform}}
\index{retransform@{retransform}!nn\_regression@{nn\_regression}}
\doxysubsubsection{\texorpdfstring{retransform()}{retransform()}}
{\footnotesize\ttfamily def nn\+\_\+regression.\+retransform (\begin{DoxyParamCaption}\item[{}]{data,  }\item[{}]{predicted\+\_\+target,  }\item[{}]{target\+\_\+keys = {\ttfamily \mbox{[}\char`\"{}Barrier\char`\"{}\mbox{]}} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Takes a DataFrame and a single-columned DataFrame added to the former with the given key.
:param data: (pandas DataFrame) DataFrame to be modified
:param predicted_target: (pandas DataFrame) DataFrame with values to be added to data
:param target_keys: (str list) key of column to be added
:return retransformed_data: (pandas DataFrame) DataFrame after concatenation of column
\end{DoxyVerb}
 